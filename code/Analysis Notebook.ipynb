{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOz5/0L/PVZWe04RSRBzoAp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction to this Notebook\n","\n","This Jupyter Notebook encompassess a series of scripts written in Python by Daniel Teixeira dos Santos, a Data Community Innovator at the Data Community of Practice ([link to my forum account](https://rcop.michaeljfox.org/u/danieltds/summary)). These scripts were written using Google Colab by accessing local files present in my Google Drive that I downloaded from LONI. These files are linked to the MJFF Research Community's GitHub repository ([link here](https://github.com/MJFF-ResearchCommunity/Useful-PPMI-Clinical-Codes))\n","\n","The goal of these scripts is to provide researchers some relevant clinical data that are extracted in a meaningful way form the data that is already available in PPMI. All the necessary input datasets can be obtained [here](https://ida.loni.usc.edu/pages/access/studyData.jsp?project=PPMI) after applying for registration for access to the PPMI data. All outputs from the analyses were removed to comply with privacy and data sahring principles. Some of these scripts were developed with the help of AI tools such as ChatGPT 4o."],"metadata":{"id":"8woFzbSOyoxy"}},{"cell_type":"markdown","source":["# Importing Google Drive"],"metadata":{"id":"GT3aJYfg_HsV"}},{"cell_type":"code","source":["# Loading Google Drive (requires login)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Setting working directory (working path for me)\n","import os\n","os.chdir(\"/content/drive/MyDrive/Colab/Useful PPMI Clinical Codes/\")\n","\n","# Installing and downloading useful modules\n","import pandas as pd # Data analysis and manipulation tool - https://pandas.pydata.org/\n","import numpy as np # Scientific computing - https://numpy.org/\n","import math # Math!\n","import glob # Needed for a search for filetypes within a folder\n","\n","# Some warning are persistent and I tend to ignore\n","import warnings\n","warnings.simplefilter(\"ignore\", UserWarning)\n","\n","# More data displayed in pandas columns\n","pd.set_option('display.max_rows', 250)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', None) # Maximum width of each column\n","pd.options.display.float_format = \"{:,.3f}\".format # Show to at most 2 decimals values\n","\n","# Print what is in the loaded directory\n","os.listdir()"],"metadata":{"id":"f2U67csL_KgD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFq21F1GONpM"},"source":["# LEDD calculation\n","\n","Levodopa Equivalent Daily Dose (LEDD) is a concept that identifies the total dosage of medications used to treat PD. It is important because it gives us information on how difficult it is to treat a specific patients. This data is already present in a PPMI data cut, however, this script also tries to produce LEDD of specific subgroups of medications such as levodopa-specific LEDD, MAO-B inhibitors, dopamina agonists etc\n","\n","The latest LEDD calculation formulas are based on: https://movementdisorders.onlinelibrary.wiley.com/doi/full/10.1002/mds.29410\n","\n","**Necessary PPMI datasets:** LEDD Concomitant Medication Log and MDS-UPDRS Part III Treatment Determination and Part III: Motor Examination\n","\n","**Last Update:** February 9, 2025"]},{"cell_type":"markdown","metadata":{"id":"Gi1nOSARgkjh"},"source":["## Reading"]},{"cell_type":"markdown","source":["MDS-UPDRS Part III. This will be used as a proxy for a merger of EVENT_ID"],"metadata":{"id":"g6eME6ndhSw8"}},{"cell_type":"code","source":["MDS3 = pd.read_csv('data/MDS-UPDRS_Part_III_09Feb2025.csv')\n","print('Lenght of the dataset:', len(MDS3))\n","MDS3.head()"],"metadata":{"id":"6KV8uluohYtg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LEDD datasheet"],"metadata":{"id":"gai3PXIVhRd2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4V1O53OEdO2U"},"outputs":[],"source":["LEDD = pd.read_csv('data/LEDD_Concomitant_Medication_Log_12Jan2025.csv')\n","print('Lenght of the dataset:', len(LEDD))\n","LEDD.head()"]},{"cell_type":"markdown","source":["**Explanation:** Differently from most PPMI notebooks, data in this dataset is not organized in EVENT_ID, so each we will need to apply the total LEDD for each EVENT_ID. Columns of interest are \"LEDTRT\" (name of the medication), \"STARTDT\" (Start Data), STOPDT (Stop Date) and \"LEDD\" (total already calculated LEDD). This script will, therefore, try to interpret this dataset and create columns that represent the LEDD for all medication times applied to each timepoint, so that it can facilitate analyses.\n","\n","However, some rows doesn't have their LEDD calculated, and some adjustments can be necessary. Also, mediciation-specific type of LEDD are not calculated (e.g. dopamine agonist, MAO-B inhibitors etc). This script will address these issues."],"metadata":{"id":"Qy0BgdthQMEw"}},{"cell_type":"markdown","metadata":{"id":"_kFNugTFe0I9"},"source":["## Adjusting Levodopa to COMT\n","\n","Entacapone enhances the half-life of levodopa, so, usually, there needs to happen a multiplication of the LEDD when someone used Entacapone Some rows have an incomplete LEDD value just saying \"LD x 0.33\" or something like that, which indicates that the total dose of levodopa must be multiplied and added that amount (example: Carbidopa/Levodopa/Entacapone, telling the doses of everyone). Other rows have only this information on multiplication but no adjacent levodopa dose (example: Entacapone).\n","\n","For privacy reasons, I can't give direct numerical examples of the patients that have this type of entry in my code, but to identify those, just look for PATNOs that have \"Carbidopa/Levodopa/Entacapone\" in the column \"LEDTRT\" and you can see that, in those patients, the LEDD column isn't calculated. It is \"LD x 0.33\" instead. You can also noticed that \"LEDDSTRMG\" brings forth the dosage of levodopa present in that compound, so we can further calculate\n"]},{"cell_type":"markdown","source":["This codes creates a LEDD for instances where entacapone formulations are combined with levodopa"],"metadata":{"id":"za4SZHnrgXhp"}},{"cell_type":"code","source":["LEDD = pd.read_csv('data/LEDD_Concomitant_Medication_Log_12Jan2025.csv')\n","LEDD.head()"],"metadata":{"id":"ZBTz3vRG5gVo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the number that appears after \"LD x\" in the \"LEDD\" column\n","LEDD['LD_multiplier'] = LEDD['LEDD'].str.extract(r'LD x (\\d+\\.\\d+)').astype(float)"],"metadata":{"id":"YmUDQ81pZ2ls"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSt2F2FwfwfM"},"source":["Adding an already converted value of LEDD in the first type of case"]},{"cell_type":"code","source":["# Function to calculate LEDD\n","def calculate_ledd_ld(row):\n","    # Check if \"levodopa\" is present in LEDTRT (case insensitive)\n","    contains_levodopa = isinstance(row['LEDTRT'], str) and 'levodopa' in row['LEDTRT'].lower()\n","\n","    # Proceed with calculation if LD_multiplier and LEDDSTRMG are not NaN and LEDTRT contains \"levodopa\"\n","    if pd.notna(row['LD_multiplier']) and pd.notna(row['LEDDSTRMG']) and contains_levodopa:\n","        result = (row['LEDDOSE'] * row['LEDDOSFRQ'] * row['LEDDSTRMG']) + \\\n","                 (row['LEDDOSE'] * row['LEDDOSFRQ'] * row['LEDDSTRMG'] * row['LD_multiplier'])\n","        return result\n","    return np.nan  # Return NaN for rows where conditions are not met\n","\n","# Running the function on all rows\n","LEDD['Calculated_LEDD_LD'] = LEDD.apply(calculate_ledd_ld, axis=1)\n","\n","# Count number of modified rows\n","num_modified = LEDD['Calculated_LEDD_LD'].notna().sum()\n","\n","# Update LEDD where Calculated_LEDD_LD is not NaN\n","LEDD.loc[pd.notna(LEDD['Calculated_LEDD_LD']), 'LEDD'] = LEDD['Calculated_LEDD_LD']\n","\n","# Print number of modified rows\n","print(f\"Number of rows modified: {num_modified}\")\n","\n","# Checking the end result and all columns involved in their calculations\n","LEDD[LEDD['LEDTRT'] == 'Carbidopa/Levodopa/Entacapone'][['LEDTRT', 'LEDDOSSTR', 'LEDDSTRMG', 'LEDDOSE', 'LEDDOSFRQ', 'LD_multiplier', 'LEDD','Calculated_LEDD_LD']].head(5)"],"metadata":{"id":"b43tf9XHTTtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now just applying this to the original LEDD column\n","# This only applies to columns where Calculated_LEDD_LD is not nan\n","# Count the number of rows where LEDD will be updated\n","num_modified = LEDD['Calculated_LEDD_LD'].notna().sum()\n","\n","# Update LEDD values where Calculated_LEDD_LD is not NaN\n","LEDD.loc[pd.notna(LEDD['Calculated_LEDD_LD']), 'LEDD'] = LEDD['Calculated_LEDD_LD']\n","\n","# Print the number of modified rows\n","print(f\"Number of rows modified: {num_modified}\")"],"metadata":{"id":"tIwhOikGUrAF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LD x 0.2, 0.33 and 0.5\n","\n","Some rows have the COMT inhibitor isolated, therefore, we need to apply the calculations to the respective levodopa dosage that matches the period the patient was taking any of those medications.\n","\n","Most common options are Entacapone (0.33) and Opicapone (0.5). However, Istradefylline, also uses a 0.2 increased conversion factor."],"metadata":{"id":"cZGoiuZOZ7-T"}},{"cell_type":"code","source":["# Identifying how many entries had one medication that needs LEDD correction\n","LEDD['LD_multiplier'].value_counts()"],"metadata":{"id":"vEviALFcR8rD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Before analysing: in order for the code to work, entries should have exactly the same duration as the COMT inhibitor specified start and stop dates. If not, these calclations won't work. Therefore, we have to subdivide into new rows.\n","\n","This script has been verified that it works correctly by selecting some specific patients and confirming that it correctly creates the necessary new rows that align with medication usage and that the original rows are deleted to not do double calculations.\n","\n","Select some specific PATNOs modified by this script to verify its feasibility\n","\n","**IMPORTANT:** as patients currently undertaking medication have a STOPDT of NaN (which invalidates the script), the first two ines of the script are a comment and a setting for the date you downloaded the dataset, so it will fill all NaN with the specified date!"],"metadata":{"id":"pRCkn4PELWcv"}},{"cell_type":"code","source":["# Input the date you downloaded the dataset (this is important for this script to work)\n","LEDD['STOPDT'] = LEDD['STOPDT'].fillna(pd.to_datetime('2025-01-01'))  # YYYY-MM-DD\n","\n","# Mark original rows\n","LEDD['Row_Type'] = 'Original'\n","\n","# Convert dates for processing\n","LEDD['STARTDT'] = pd.to_datetime(LEDD['STARTDT'], format='%m/%Y', errors='coerce')\n","LEDD['STOPDT'] = pd.to_datetime(LEDD['STOPDT'], format='%m/%Y', errors='coerce')\n","\n","# Identify patients (PATNO) with a non-NaN LD_multiplier\n","patients_with_ldx = LEDD.loc[LEDD['LD_multiplier'].notna(), 'PATNO'].unique()\n","\n","# Create lists to store new and junk rows\n","new_rows = []\n","junk_rows = []\n","modified_patnos = set()  # Track PATNOs where at least one change occurred\n","\n","# Process each patient separately\n","for patno in patients_with_ldx:\n","    # Extract the periods where the patient has a valid LD_multiplier\n","    ldx_periods = LEDD[(LEDD['PATNO'] == patno) & (LEDD['LD_multiplier'].notna())][['STARTDT', 'STOPDT', 'LD_multiplier']]\n","\n","    # Extract all Levodopa rows for the patient\n","    levodopa_rows = LEDD[(LEDD['PATNO'] == patno) & (LEDD['LEDTRT'].str.contains('Levodopa', case=False, na=False))]\n","\n","    for _, ldx in ldx_periods.iterrows():\n","        ld_start, ld_stop, ld_multiplier = ldx['STARTDT'], ldx['STOPDT'], ldx['LD_multiplier']\n","\n","        for _, levodopa in levodopa_rows.iterrows():\n","            levo_start, levo_stop = levodopa['STARTDT'], levodopa['STOPDT']\n","\n","            # Identify non-exact but overlapping matches\n","            if (levo_start < ld_stop) and (levo_stop > ld_start) and not ((levo_start == ld_start) and (levo_stop == ld_stop)):\n","\n","                # Move the original row to the junk dataset before replacing it\n","                junk_rows.append(levodopa.copy())\n","\n","                # Mark PATNO as modified\n","                modified_patnos.add(patno)\n","\n","                # First row: Exact match to LD multiplier time\n","                exact_match = levodopa.copy()\n","                exact_match['STARTDT'] = ld_start\n","                exact_match['STOPDT'] = ld_stop\n","                exact_match['Row_Type'] = 'Generated'\n","                new_rows.append(exact_match)\n","\n","                # Second row: Period before LD multiplier medication\n","                if levo_start < ld_start:\n","                    before_match = levodopa.copy()\n","                    before_match['STOPDT'] = ld_start\n","                    before_match['Row_Type'] = 'Generated'\n","                    new_rows.append(before_match)\n","\n","                # Third row: Period after LD multiplier medication\n","                if (levo_stop is pd.NaT) or (levo_stop > ld_stop):\n","                    after_match = levodopa.copy()\n","                    after_match['STARTDT'] = ld_stop\n","                    after_match['Row_Type'] = 'Generated'\n","                    new_rows.append(after_match)\n","\n","# Convert the new and junk rows into DataFrames\n","new_rows_df = pd.DataFrame(new_rows)\n","junk_rows_df = pd.DataFrame(junk_rows)\n","\n","# Remove the junk rows from the main dataset\n","LEDD = LEDD[~LEDD.index.isin(junk_rows_df.index)]\n","\n","# Append the generated rows to the original dataset\n","LEDD = pd.concat([LEDD, new_rows_df], ignore_index=True)\n","\n","# Sort the dataset by PATNO and STARTDT to maintain alignment\n","LEDD = LEDD.sort_values(by=['PATNO', 'STARTDT']).reset_index(drop=True)\n","\n","# Print summary statistics\n","print(f\"Number of unique PATNOs modified: {len(modified_patnos)}\")\n","print(f\"Total number of new rows added: {len(new_rows_df)}\")"],"metadata":{"id":"M3gwboItT2w6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we are going to prepare to run the script that recalculates the LEDD. But first, we need to set different possibilities for levodopa names"],"metadata":{"id":"kQN8WJrqUPLW"}},{"cell_type":"code","source":["# Creating the list\n","levodopa_names = ['Levodopa', 'Dhivy', 'Duodopa', 'Duopa', 'Inbrija',\n","                  'Parcopa','Prolopa','Rytary','Sinemet','Stalevo']\n","\n","# Create regex pattern by joining the list elements with \"|\"\n","levodopa_pattern = '|'.join(levodopa_names)\n","\n","# Seeing the result\n","print(levodopa_pattern)"],"metadata":{"id":"dwOHJ4tuI1SI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6v3OrggYfcok"},"source":["Now the real deal: multiplying according levodopa LEDD in which the timestamp is similar"]},{"cell_type":"code","source":["# Initialize 'Multiplied' column\n","LEDD['Multiplied'] = 'No'\n","\n","# Creating the \"Original_LEDD\" values to check if any inconsistencies may happen\n","LEDD['LEDD'] = LEDD['LEDD'].astype(str)\n","\n","# Extract numeric values only when \"LD\" is NOT in the string\n","LEDD['Original_LEDD'] = np.where(\n","    LEDD['LEDD'].str.contains('LD', case=False, na=False),\n","    np.nan,\n","    LEDD['LEDD'].str.extract(r'(\\d+\\.\\d+|\\d+)', expand=False).astype(float)\n",")\n","\n","# Iterate over unique PATNO values to process each patient separately\n","for patno in LEDD['PATNO'].unique():\n","    # Filter dataset for the specific patient\n","    patient_data = LEDD[LEDD['PATNO'] == patno]\n","\n","    # Identify rows with 'LD x' in LEDD for the specific patient\n","    rows_with_ldx = patient_data[patient_data['LEDD'].str.contains('LD x', na=False)]\n","\n","    # Iterating over identified rows\n","    for index, row in rows_with_ldx.iterrows():\n","        multiplier = row['LD_multiplier']\n","        start_date = row['STARTDT']\n","        stop_date = row['STOPDT']\n","\n","        # Identify corresponding Levodopa rows within the same date range for the same patient\n","        corresponding_rows = LEDD[\n","            (LEDD['PATNO'] == patno) &  # Ensuring only within the same patient\n","            (LEDD['LEDTRT'].str.contains(levodopa_pattern, case=False, na=False)) &\n","            (LEDD['STARTDT'] == start_date) &\n","            ((LEDD['STOPDT'] == stop_date) | (LEDD['STOPDT'].isna() & pd.isna(stop_date))) &\n","            (LEDD['Multiplied'] == 'No')\n","        ]\n","\n","        # Apply the multiplication logic correctly\n","        for corr_index, corr_row in corresponding_rows.iterrows():\n","            original_ledd = LEDD.loc[corr_index, 'Original_LEDD']\n","            if pd.notna(multiplier):  # Ensure multiplier is not NaN\n","                new_ledd = original_ledd + (original_ledd * multiplier)\n","                LEDD.loc[corr_index, 'LEDD'] = new_ledd\n","                LEDD.loc[corr_index, 'Multiplied'] = 'Yes'"],"metadata":{"id":"1eWeD56gfZiR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Specific medication LEDD and joining to the timepoint organization\n","\n","This part of the script accomplishes two different goals: first it merges the data present in the LEDD script in a way that is is aligned with the EVENT_ID in the dataset (BL, V02, V04 etc). For this, we use the MDS-UPDRS 3 questionnaire as a proxy to gather these timeframes, as it seems to be one of the most complete questionnaires. Second, it calculates medication_specific LEDD based on synthax understanding. It calculates for levodopa, MAO-B, amantadine, anticholinergics etc"],"metadata":{"id":"ta2Pzdi18lQC"}},{"cell_type":"markdown","source":["This script is just to showcase how you can identify the different ways levodopa are written. I did a manual check for most medication types that will be presented below to ensure most of them could be included in LEDD-specific medication calculations"],"metadata":{"id":"S71NJ8b_awrR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pUuBvRtcf9z0"},"outputs":[],"source":["# Selecting rows where the \"LEDTRT\" column contains 'Levodopa'\n","levodopa_rows = LEDD[LEDD['LEDTRT'].str.contains('Levodopa', case=False, na=False)]\n","\n","# Printing or further processing the selected rows\n","levodopa_rows['LEDTRT'].value_counts().index.tolist()[0:5]"]},{"cell_type":"markdown","metadata":{"id":"gpt78OzLgH2Z"},"source":["## Uniting LEDD to timepoints"]},{"cell_type":"code","source":["# Defining names for specific categories\n","# Levodopa\n","levodopa_names = ['Levodopa', 'Dhivy', 'Duodopa', 'Duopa', 'Inbrija',\n","                  'Parcopa','Prolopa','Rytary','Sinemet','Stalevo']\n","\n","# Create a regex pattern that matches any of the terms\n","levodopopa_pattern = '|'.join(levodopa_names)\n","\n","# Dopamine agonists\n","dopamine_agonist_names = ['Pramipexol', 'Mirapex', 'Mirapexin', 'Sifrol',\n","                          'Ropirinol', 'Requip', 'Rotigotin', 'Neupro',\n","                          'Apomorphin', 'Apokyn']\n","\n","# Create a regex pattern that matches any of the terms\n","dopamine_agonist_pattern = '|'.join(dopamine_agonist_names)\n","\n","# MAO-B\n","maob_names = ['Selegilin', 'Eldepryl', 'Zelapar', 'Rasagilin', 'Azilect'\n","                          'Safinamid', 'Xadago']\n","\n","# Create a regex pattern that matches any of the terms\n","maob_pattern = '|'.join(maob_names)\n","\n","# COMT\n","comt_names = ['Entacapon', 'Comtan', 'Tolcapon', 'Tasmar',\n","              'Opicapon', 'Ongentys']\n","\n","# Create a regex pattern that matches any of the terms\n","comt_pattern = '|'.join(comt_names)\n","\n","# Muscarinic antagonist\n","anticholingergic_names = ['Trihexyphenidyl', 'Artanis', 'Biperiden', 'Akineton']\n","\n","# Create a regex pattern that matches any of the terms\n","anticholingergic_pattern = '|'.join(anticholingergic_names)\n","\n","# Amantadine (some typos present in the dataset, so giving all options)\n","amantadine_names = ['AMANDATINE', 'AMANDTADINE', 'AMANTADIN', 'AMANTADIN 100',\n","                    'AMANTADIN 150', 'AMANTADINA', 'AMANTADINE', 'AMANTADINE (100 MG)',\n","                    'AMANTADINE 100 MG', 'AMANTADINE 100MG', 'AMANTADINE HCL',\n","                    'AMANTADINE09', 'GOCOVERI', 'GOCOVRI', 'GOCOVRI 137 MG',\n","                    'GOCOVRI ER', 'Gocovri (Amantadine CR )', 'Gocovri (Amantadine CR)',\n","                     'OSMOLEX ER', 'Osmolex (Amantadine ER)']\n","\n","# Create a regex pattern that matches any of the terms\n","amantadine_pattern = '|'.join(amantadine_names)\n","\n","# Creating lists of names for drugs\n","levodopa_values = LEDD[LEDD['LEDTRT'].str.contains(levodopopa_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()\n","dopamine_agonist_values = LEDD[LEDD['LEDTRT'].str.contains(dopamine_agonist_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()\n","maob_values = LEDD[LEDD['LEDTRT'].str.contains(maob_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()\n","comt_values = LEDD[LEDD['LEDTRT'].str.contains(comt_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()\n","anticholingergic_values = LEDD[LEDD['LEDTRT'].str.contains(anticholingergic_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()\n","amantadine_values = LEDD[LEDD['LEDTRT'].str.contains(amantadine_pattern, case=False, regex=True)]['LEDTRT'].drop_duplicates().tolist()"],"metadata":{"id":"qozjcDQme4bv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the date columns to datetime format\n","MDS3['INFODT'] = pd.to_datetime(MDS3['INFODT'], format='%m/%Y')\n","LEDD['STARTDT'] = pd.to_datetime(LEDD['STARTDT'], format='%m/%Y')\n","LEDD['STOPDT'] = pd.to_datetime(LEDD['STOPDT'], format='%m/%Y', errors='coerce')  # Handle NaN\n","\n","# Convert 'LEDD' column to numeric\n","LEDD['LEDD'] = pd.to_numeric(LEDD['LEDD'], errors='coerce')\n","\n","# Function to calculate LEDD sums for specific medication categories\n","def calculate_ledd_sums(relevant_meds, values_list):\n","    return relevant_meds[relevant_meds['LEDTRT'].str.lower().isin([val.lower() for val in values_list])]['LEDD'].sum()\n","\n","# Initialize lists to collect results\n","led_values = []\n","amantadine_values_list = []\n","levodopa_values_list = []\n","dopamine_agonist_values_list = []\n","maob_values_list = []\n","comt_values_list = []\n","anticholingergic_values_list = []\n","\n","# Iterate through unique patients in MDS3\n","for patno in MDS3['PATNO'].unique():\n","    patient_mds3 = MDS3[MDS3['PATNO'] == patno]\n","    patient_ledd = LEDD[LEDD['PATNO'] == patno]\n","\n","    for index, row in patient_mds3.iterrows():\n","        infodt = row['INFODT']\n","        relevant_meds = patient_ledd[(patient_ledd['STARTDT'] <= infodt) &\n","                                     ((patient_ledd['STOPDT'] >= infodt) | pd.isna(patient_ledd['STOPDT']))]\n","\n","        # Sum the total LEDD values\n","        led_values.append(relevant_meds['LEDD'].sum())\n","\n","        # Sum the LEDD values for the specified 'LEDTRT' names for each category\n","        amantadine_values_list.append(calculate_ledd_sums(relevant_meds, amantadine_values))\n","        levodopa_values_list.append(calculate_ledd_sums(relevant_meds, levodopa_values))\n","        dopamine_agonist_values_list.append(calculate_ledd_sums(relevant_meds, dopamine_agonist_values))\n","        maob_values_list.append(calculate_ledd_sums(relevant_meds, maob_values))\n","        comt_values_list.append(calculate_ledd_sums(relevant_meds, comt_values))\n","        anticholingergic_values_list.append(calculate_ledd_sums(relevant_meds, anticholingergic_values))\n","\n","# Assign the collected results back to the DataFrame\n","MDS3['LEDD'] = led_values\n","MDS3['AMANTADINE_LEDD'] = amantadine_values_list\n","MDS3['LEVODOPA_LEDD'] = levodopa_values_list\n","MDS3['DOPAMINE_AGONIST_LEDD'] = dopamine_agonist_values_list\n","MDS3['MAOB_LEDD'] = maob_values_list\n","MDS3['COMT_LEDD'] = comt_values_list\n","MDS3['ANTICHOLINERGIC_LEDD'] = anticholingergic_values_list\n","\n","MDS3[['PATNO','INFODT','LEDD', 'AMANTADINE_LEDD', 'DOPAMINE_AGONIST_LEDD', 'MAOB_LEDD', 'COMT_LEDD', 'ANTICHOLINERGIC_LEDD', 'LEVODOPA_LEDD']].head()"],"metadata":{"id":"CXFJjKUlpj0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the date columns to datetime format\n","MDS3['INFODT'] = pd.to_datetime(MDS3['INFODT'], format='%m/%Y')\n","LEDD['STARTDT'] = pd.to_datetime(LEDD['STARTDT'], format='%m/%Y')\n","LEDD['STOPDT'] = pd.to_datetime(LEDD['STOPDT'], format='%m/%Y', errors='coerce')  # Handle NaN\n","\n","# Convert 'LEDD' column to numeric\n","LEDD['LEDD'] = pd.to_numeric(LEDD['LEDD'], errors='coerce')\n","\n","# Function to calculate LEDD sums for specific medication categories\n","def calculate_ledd_sums(relevant_meds, values_list):\n","    return relevant_meds[relevant_meds['LEDTRT'].str.lower().isin([val.lower() for val in values_list])]['LEDD'].sum()\n","\n","# Function to check COMT inhibitor presence\n","def check_comt_inhibitor(relevant_meds, comt_names):\n","    return \"Yes\" if relevant_meds['LEDTRT'].str.lower().isin([val.lower() for val in comt_names]).any() else \"No\"\n","\n","# Initialize lists to collect results\n","led_values = []\n","amantadine_values_list = []\n","levodopa_values_list = []\n","dopamine_agonist_values_list = []\n","maob_values_list = []\n","comt_presence_list = []  # Store Yes/No instead of sum\n","anticholingergic_values_list = []\n","\n","# Iterate through unique patients in MDS3\n","for patno in MDS3['PATNO'].unique():\n","    patient_mds3 = MDS3[MDS3['PATNO'] == patno]\n","    patient_ledd = LEDD[LEDD['PATNO'] == patno]\n","\n","    for index, row in patient_mds3.iterrows():\n","        infodt = row['INFODT']\n","        relevant_meds = patient_ledd[(patient_ledd['STARTDT'] <= infodt) &\n","                                     ((patient_ledd['STOPDT'] >= infodt) | pd.isna(patient_ledd['STOPDT']))]\n","\n","        # Sum the total LEDD values\n","        led_values.append(relevant_meds['LEDD'].sum())\n","\n","        # Sum the LEDD values for the specified 'LEDTRT' names for each category\n","        amantadine_values_list.append(calculate_ledd_sums(relevant_meds, amantadine_values))\n","        levodopa_values_list.append(calculate_ledd_sums(relevant_meds, levodopa_values))\n","        dopamine_agonist_values_list.append(calculate_ledd_sums(relevant_meds, dopamine_agonist_values))\n","        maob_values_list.append(calculate_ledd_sums(relevant_meds, maob_values))\n","        anticholingergic_values_list.append(calculate_ledd_sums(relevant_meds, anticholingergic_values))\n","\n","        # Check for COMT inhibitor presence\n","        comt_presence_list.append(check_comt_inhibitor(relevant_meds, comt_values))\n","\n","# Assign the collected results back to the DataFrame\n","MDS3['LEDD'] = led_values\n","MDS3['AMANTADINE_LEDD'] = amantadine_values_list\n","MDS3['LEVODOPA_LEDD'] = levodopa_values_list\n","MDS3['DOPAMINE_AGONIST_LEDD'] = dopamine_agonist_values_list\n","MDS3['MAOB_LEDD'] = maob_values_list\n","MDS3['COMT_INHIBITOR'] = comt_presence_list  # Changed from sum to Yes/No\n","MDS3['ANTICHOLINERGIC_LEDD'] = anticholingergic_values_list\n","\n","# Display the results\n","MDS3[['PATNO','INFODT','LEDD', 'AMANTADINE_LEDD', 'DOPAMINE_AGONIST_LEDD', 'MAOB_LEDD', 'COMT_INHIBITOR', 'ANTICHOLINERGIC_LEDD', 'LEVODOPA_LEDD']].head()"],"metadata":{"id":"I8s_3yxOem8N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exporting"],"metadata":{"id":"ynAuX8c2cqjb"}},{"cell_type":"code","source":["# Subsetting the dataset to important variables\n","LEDD_dataset = MDS3[['PATNO','INFODT','LEDD', 'AMANTADINE_LEDD', 'DOPAMINE_AGONIST_LEDD', 'MAOB_LEDD', 'COMT_INHIBITOR', 'ANTICHOLINERGIC_LEDD', 'LEVODOPA_LEDD']]\n","LEDD_dataset.head()"],"metadata":{"id":"zIrsgt7rjQ4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Exporting\n","LEDD_dataset.to_csv('data/LEDD_Dataset.csv', index=False)"],"metadata":{"id":"gO5fm3AWcspt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gXWddGqI3Ldo"},"source":["# Levodopa responsiveness\n","\n","Levodopa responsiveness is a very interesting marker that different studies have approached (example: https://pubmed.ncbi.nlm.nih.gov/38898616/). The PPMI protocol states that, whenever possible, patients should be evaluated both in the OFF and ON states. In that way, we can calculate levodopa challenge responses by using the formula: response = (off - on) / off x 100.\n","\n","**Necessary PPMI datasets:** MDS-UPDRS Part III Treatment Determination and Part III: Motor Examination\n","\n","**Last Update:** February 9, 2025"]},{"cell_type":"markdown","metadata":{"id":"mX9s1vYZLQna"},"source":["## Organizing"]},{"cell_type":"markdown","metadata":{"id":"JP0cxU2FPWqG"},"source":["### General read and view"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC229wdVB8vK"},"outputs":[],"source":["MDS3 = pd.read_csv('data/MDS-UPDRS_Part_III_09Feb2025.csv')\n","print('Lenght of the dataset:', len(MDS3))\n","MDS3.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqVvHXYUwriv"},"outputs":[],"source":["# Define concepts with their corresponding columns\n","# This can be useful to calculate characteristic-specific levodopa responses\n","concepts = {\n","    'Rigidity': [\"NP3RIGLL\", \"NP3RIGLU\", \"NP3RIGN\", \"NP3RIGRL\", \"NP3RIGRU\"], # 3.3 (all elements)\n","    \"Tremor\": [\"NP3KTRML\", \"NP3KTRMR\", \"NP3PTRML\", \"NP3PTRMR\", \"NP3RTALJ\", \"NP3RTALL\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTARU\", \"NP3RTCON\"], # 3.15 + 3.16 + 3.17 + 3.18\n","    \"Gait_and_Posture\": [\"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\", \"NP3POSTR\"], # 3.9 + 3.10 + 3.11 + 3.12 + 3.13\n","    \"Bradykinesia\": [\"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\", \"NP3TTAPL\", \"NP3LGAGR\", \"NP3LGAGL\", \"NP3BRADY\"],# \t3.4 + 3.5 + 3.6 + 3.7 + 3.8 + 3.14\n","    'All_MDS3': [\"NP3SPCH\", \"NP3FACXP\", \"NP3RIGN\", \"NP3RIGRU\", \"NP3RIGLU\", \"NP3RIGRL\", \"NP3RIGLL\",\n","    \"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\",\n","    \"NP3TTAPL\", \"NP3LGAGR\", \"NP3LGAGL\", \"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\",\n","    \"NP3POSTR\", \"NP3BRADY\", \"NP3PTRMR\", \"NP3PTRML\", \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\",\n","    \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \"NP3RTALJ\", \"NP3RTCON\"]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PNS_SOfwtO2"},"outputs":[],"source":["# Function to compute the sum, considering NaN\n","def sum_with_nan(series):\n","    if series.isna().any():\n","        return np.nan\n","    else:\n","        return series.sum()\n","\n","concepts_list = []\n","\n","# Add new columns with the sum of values for each concept\n","for concept, columns in concepts.items():\n","    sum_column = concept\n","    concepts_list.append(sum_column)\n","    MDS3[sum_column] = MDS3[columns].apply(sum_with_nan, axis=1)"]},{"cell_type":"code","source":["# Let's check the overall distribution of the PDSTATE (situation in which the patient was examined)\n","MDS3['PDSTATE'].value_counts()"],"metadata":{"id":"BCap9oFlGQEa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check how many different entries (more than one for patient) have at least 2 MDS evaluations (one in the OFF and one in the ON states)"],"metadata":{"id":"hrPQhVbxhzJJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTtY5lpSEAQ6"},"outputs":[],"source":["# Group by PATNO and EVENT_ID and filter groups with more than one entry\n","duplicates = MDS3.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) > 1)\n","\n","# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n","result_test = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n","    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n","    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n","    'EXAMTM': lambda x: tuple(x), # Time of NUPDRS3 exam\n","    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n","    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n","    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n","    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n","    'OFFNORSN': lambda x: tuple(x), # Reason OFF exam not performed\n","    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n","    'ONEXAM': lambda x: tuple(x), # ON exam performed\n","    'ONNORSN': lambda x: tuple(x), # Reason ON exam not performed\n","    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n","    'PDMEDDT': lambda x: tuple(x), # Date of most recent PD med dose before exam\n","    'PDMEDTM': lambda x: tuple(x), # Time of most recent PD med dose before exam\n","}).reset_index()\n","\n","print('Lenght of the dataset considering at least 2 evaluations:', len(result_test))\n","result_test.head()"]},{"cell_type":"markdown","source":["Check how many different entries (more than one for patient) have at least 3 MDS evaluations (one in the OFF and one in the ON states).\n","\n","This is unusual, but the number is low. Did this just to check how data are displayed."],"metadata":{"id":"sY65-iefh7XT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTHjrGyVO4zy"},"outputs":[],"source":["# Group by PATNO and EVENT_ID and filter groups with more than one entry\n","duplicates = MDS3.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) > 2)\n","\n","# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n","result_test = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n","    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n","    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n","    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n","    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n","    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n","    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n","    'OFFNORSN': lambda x: tuple(x), # Reason OFF exam not performed\n","    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n","    'ONEXAM': lambda x: tuple(x), # ON exam performed\n","    'ONNORSN': lambda x: tuple(x), # Reason ON exam not performed\n","    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n","    'PDMEDDT': lambda x: tuple(x), # Date of most recent PD med dose before exam\n","    'PDMEDTM': lambda x: tuple(x), # Time of most recent PD med dose before exam\n","}).reset_index()\n","\n","print('Lenght of the dataset considering more than 2 evaluations:', len(result_test))\n","result_test.head()"]},{"cell_type":"markdown","metadata":{"id":"gTqQTuw2PaJh"},"source":["### Missing correction\n","\n","Missing values in the MDS-UPDRS can be written as 101 (Unable to Rate). Let's identify those and treat them as NaN for our analysis not to be biased by those high numbers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdnrXA42MOiP"},"outputs":[],"source":["# Dataset has some \"101\", which are \"Unable to Rate\"\n","MDS3['NP3RIGLL'].value_counts(dropna=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VaRjqVbMa-j"},"outputs":[],"source":["# Converting unables to rate to nan\n","MDS3 = MDS3.replace(101,np.nan)\n","\n","# Forcing to become float, ignore errors\n","MDS3 = MDS3.apply(pd.to_numeric, errors='ignore')\n","\n","# Checking\n","MDS3['NP3RIGLL'].value_counts(dropna=False)"]},{"cell_type":"markdown","metadata":{"id":"er_StgOzPdyB"},"source":["### DBS categories\n","\n","Patients also undergo DBS as this is informed in the MDS3 scale. We will want, in this code, generate separate values for evaluations that had a DBS and evaluations without a DBS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxY8tVcRPhV-"},"outputs":[],"source":["print('Length of the dataset before removing DBS:', len(MDS3))\n","MDS3_nodbs = MDS3[MDS3['DBSYN'].isin([0, np.nan])].reset_index(drop=True)\n","print('Length of the dataset after removing DBS:', len(MDS3_nodbs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTGdIP6IxA0g"},"outputs":[],"source":["print('Length of the dataset before subsetting by DBS:', len(MDS3))\n","MDS3_dbs = MDS3[MDS3['DBSYN'].isin([1])].reset_index(drop=True)\n","print('Length of the dataset after subsetting by DBS:', len(MDS3_dbs))"]},{"cell_type":"markdown","metadata":{"id":"6tIwup-yQJs6"},"source":["## Calculating response (no DBS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ER0375dQMK2"},"outputs":[],"source":["# Group by PATNO and EVENT_ID and filter groups with more than one entry\n","duplicates = MDS3_nodbs.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) == 2)\n","\n","# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n","result = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n","    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n","    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n","    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n","    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n","    'ONEXAM': lambda x: tuple(x), # ON exam performed\n","    'Rigidity': lambda x: tuple(x), # Rigidity\n","    'Tremor': lambda x: tuple(x), # Tremor\n","    'Gait_and_Posture': lambda x: tuple(x), # Gait and Posture\n","    'Bradykinesia': lambda x: tuple(x), # Bradykinesia\n","    'All_MDS3': lambda x: tuple(x), # MDS_3 Complete\n","}).reset_index()\n","\n","print('Lenght of the dataset considering exactly 2 evaluations:', len(result))\n","result.head()"]},{"cell_type":"markdown","source":["Main function to calculate the response. It uses the tuples of OFF and ON to calculate these responses, then generates new columns detailing the actual responses. There are also other columns that helps us better understaning what is happening, such as \"Time_since_levodopa\", which helps us be sure that the responses are correctly calculating OFF versus ON responses, and not the opposite.\n","\n","The lowest HRPOSTMED (hours after last medication) is used to define the ON state"],"metadata":{"id":"FLx-cVZijLUz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QeI-M4VSd9s"},"outputs":[],"source":["# Define the function to calculate the response\n","def calculate_response(on, off):\n","    if pd.isna(on) or pd.isna(off) or off == 0:\n","        return np.nan\n","    return ((off - on) / off) * 100\n","\n","# Define a function to round values and handle errors\n","def round_to_int(value):\n","    try:\n","        return int(round(value))\n","    except (ValueError, TypeError):\n","        return np.nan\n","\n","# Function to process the dataset\n","def process_dataset(df, concepts_list):\n","    new_columns = []\n","    df['Time_since_levodopa'] = df['HRPOSTMED'].apply(lambda x: min(x) if not any(pd.isna(v) for v in x) else np.nan) * 60  # Convert to minutes\n","    df['Time_since_levodopa'] = df['Time_since_levodopa'].apply(round_to_int)\n","    for var in concepts_list:\n","        new_col_name = f'{var}_resp'\n","        new_columns.append(new_col_name)\n","        df[new_col_name] = df.apply(lambda row: calculate_response(\n","            row[var][0] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][1],  # on\n","            row[var][1] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][0]   # off\n","        ) if not any(pd.isna(v) for v in row['HRPOSTMED']) else np.nan, axis=1)\n","    return df, new_columns\n","\n","# Assuming result is your DataFrame\n","levodopa_response, newcols = process_dataset(result, concepts_list)\n","\n","# Display the processed DataFrame\n","levodopa_response.head()"]},{"cell_type":"markdown","metadata":{"id":"xTd3vogqWlQx"},"source":["There are some negative values, however, they are a minority of the data. Some of the most significant ones can be typos, and other just a slight paradoxical worsening / variation due to clinician's judgment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwr09tmdWlBj"},"outputs":[],"source":["levodopa_response[newcols].describe(include='all')"]},{"cell_type":"markdown","metadata":{"id":"J5KD-r3pWnJG"},"source":["Let's check thesep patients as an example"]},{"cell_type":"code","source":["# First, let's have a general idea of some patients with negative responses\n","print(len(levodopa_response[levodopa_response['All_MDS3_resp'] < 0]))\n","levodopa_response[levodopa_response['All_MDS3_resp'] < 0].head(10)[['PDSTATE','HRPOSTMED','All_MDS3','All_MDS3_resp']]"],"metadata":{"id":"kFwCdw-okLen"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Second, let's have a general idea of some patients with EXTREME negative responses\n","print(len(levodopa_response[levodopa_response['All_MDS3_resp'] < -100]))\n","levodopa_response[levodopa_response['All_MDS3_resp'] < -100].head(10)[['PDSTATE','HRPOSTMED','All_MDS3','All_MDS3_resp']]"],"metadata":{"id":"RFk8d3r4oIjD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, most patients with responses between -100 and 0 have just a mild paradoxical response or variation due to clinical judgment. However, most patients < -100 probably have typos that invalidated the analysis. Fortunately, thery are only a few.\n","\n","I will not remove those, but **I highly suggest you take that into account in your analysis**"],"metadata":{"id":"_d9clp_toVzA"}},{"cell_type":"markdown","source":["Exporting"],"metadata":{"id":"3kdmmJ2wxwqW"}},{"cell_type":"code","source":["# Exporting\n","levodopa_response.to_csv('data/levodopa_challenge_no_DBS.csv', index=False)"],"metadata":{"id":"6LkMtKNixx39"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fqafPVYxUSY"},"source":["## Calculating response (DBS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEARecrSxUSY"},"outputs":[],"source":["# Group by PATNO and EVENT_ID and filter groups with more than one entry\n","duplicates = MDS3_dbs.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) == 2)\n","\n","# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n","result = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n","    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n","    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n","    'EXAMTM': lambda x: tuple(x), # Time of NUPDRS3 exam\n","    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n","    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n","    'ONEXAM': lambda x: tuple(x), # ON exam performed\n","    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n","    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n","    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n","    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n","    'Rigidity': lambda x: tuple(x), # Rigidity\n","    'Tremor': lambda x: tuple(x), # Tremor\n","    'Gait_and_Posture': lambda x: tuple(x), # Gait and Posture\n","    'Bradykinesia': lambda x: tuple(x), # Bradykinesia\n","    'All_MDS3': lambda x: tuple(x), # MDS_3 Complete\n","}).reset_index()\n","\n","print('Lenght of the dataset considering exactly 2 evaluations:', len(result))\n","result.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbTi9oEcxUSZ"},"outputs":[],"source":["# Define the function to calculate the response\n","def calculate_response(on, off):\n","    if pd.isna(on) or pd.isna(off) or off == 0:\n","        return np.nan\n","    return ((off - on) / off) * 100\n","\n","# Define a function to round values and handle errors\n","def round_to_int(value):\n","    try:\n","        return int(round(value))\n","    except (ValueError, TypeError):\n","        return np.nan\n","\n","# Function to process the dataset\n","def process_dataset(df, concepts_list):\n","    new_columns = []\n","    df['Time_since_levodopa'] = df['HRPOSTMED'].apply(lambda x: min(x) if not any(pd.isna(v) for v in x) else np.nan) * 60  # Convert to minutes\n","    df['Time_since_levodopa'] = df['Time_since_levodopa'].apply(round_to_int)\n","    for var in concepts_list:\n","        new_col_name = f'{var}_resp'\n","        new_columns.append(new_col_name)\n","        df[new_col_name] = df.apply(lambda row: calculate_response(\n","            row[var][0] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][1],  # on\n","            row[var][1] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][0]   # off\n","        ) if not any(pd.isna(v) for v in row['HRPOSTMED']) else np.nan, axis=1)\n","    return df, new_columns\n","\n","# Assuming result is your DataFrame\n","levodopa_response, newcols = process_dataset(result, concepts_list)\n","\n","# Display the processed DataFrame\n","filtered_df = levodopa_response[levodopa_response['Time_since_levodopa'].notna()]\n","\n","# Count the unique values in the 'Time_since_levodopa' column\n","unique_patients_levodopa = filtered_df['Time_since_levodopa'].nunique()\n","print('Length of entire dataset:', len(levodopa_response))\n","print('Length of subsetted dataset:', len(filtered_df))\n","print('Number of unique patients using DBS that took levodopa in a challenge:', unique_patients_levodopa)\n","\n","# Showing the subsetted dataset\n","filtered_df.head()"]},{"cell_type":"code","source":["# Exporting\n","levodopa_response.to_csv('data/levodopa_challenge_DBS.csv', index=False)"],"metadata":{"id":"vt0Cq29jpJ2b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dOmudaSJNaos"},"source":["# Medical Conditions\n","\n","Several medical conditions are associated with a higher PD risk and/or progression (examples: https://pubmed.ncbi.nlm.nih.gov/36865411/ and https://pubmed.ncbi.nlm.nih.gov/33682937/). So having a way to understand in more detail each patient's diagnosis may be useful for correlation analyses.\n","\n","**Necessary PPMI datasets:** Medical Conditions Log and MDS-UPDRS Part III Treatment Determination and Part III: Motor Examination\n","\n","**Last Update:** February 9, 2025"]},{"cell_type":"markdown","metadata":{"id":"vkX6ekYqYeFJ"},"source":["## Reading"]},{"cell_type":"markdown","source":["Reading MDS data to use as a surrogate for the timepoints"],"metadata":{"id":"wWI6YpAoqIee"}},{"cell_type":"code","source":["# Using MDS3 as a timepoint proxy\n","MDS3 = pd.read_csv('data/MDS-UPDRS_Part_III_09Feb2025.csv')\n","print('Lenght of the dataset:', len(MDS3))\n","MDS3.head()"],"metadata":{"id":"xidW9NV8qAWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kcka2kayNcP0"},"outputs":[],"source":["# Reading the medical conditions dataset\n","conditions = pd.read_csv('data/Medical_Conditions_Log_09Feb2025.csv')\n","print('Lenght of the dataset:', len(conditions))\n","conditions.head()"]},{"cell_type":"markdown","metadata":{"id":"RgDY5lQiRFMS"},"source":["This and other datasets don't have information in the EVENT_ID format, however, they provide the \"INFODT\" (Assessment Date), \"RESYR\" (Year of Resolution), \"MHDIAGYR\" (Year of Diagnosis), \"MHDIAGDT\" (Date ate diagnosis) and \"RESOLVD\" (Resolved).\n","\n","The most logical way to extract this information, I think, is to identify if it was present in the same time assessments of the EVENT_ID, then label if the patient had or not this condition by that time (BL, V02, V04 etc).\n","\n","So, for a patient to have a condition, it must: (1) have this diagnosis in a period earlier or equal to the EVENT_ID - \"MHTERM\" + \"MHDIAGDT\" and (2) not having resolved this by the time of this \"RESOLVD\""]},{"cell_type":"markdown","metadata":{"id":"g3_MBWTGS58n"},"source":["Diabetes example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iezJFQ9TuY3"},"outputs":[],"source":["# Getting columns with the diagnosis we want\n","elements = ['diabetes']\n","\n","# Converting 'elements' to lowercase to ensure case-insensitive matching\n","elements_lower = [element.lower() for element in elements]\n","\n","# Selecting the patients that have one of the criterias\n","tempdf = conditions[conditions['MHTERM'].astype(str).str.lower().apply(lambda x: any(element in x for element in elements))]\n","print('Lenght of patients with the desired condition:', len(tempdf))\n","print('Different values of the obtained dataset:', list(set(tempdf['MHTERM']))) # Printing without duplicates\n","tempdf.head()"]},{"cell_type":"markdown","metadata":{"id":"KHff2egvbjf9"},"source":["## Definitions\n","\n","For this code, we will be using the example for the Charlson comorbidity index (https://www.mdcalc.com/calc/3917/charlson-comorbidity-index-cci) and will extract the conditions present in that score. Osteoporosis was added also added as a test.\n","\n","Of course, you could modify this to any condition of your liking, just having to think about all the different names this could be written in the dataset in order to extract it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iz8-rS-Y5fQJ"},"outputs":[],"source":["# List of Charlson Comorbidity Index conditions\n","charlson_conditions = {\n","    'Myocardial Infarction': ['myocardial infarction', 'heart attack', 'MI'],\n","    'Congestive Heart Failure': ['heart failure', 'CHF', 'congestive heart failure'],\n","    'Peripheral Vascular Disease': ['peripheral vascular disease', 'PVD', 'peripheral artery disease'],\n","    'Cerebrovascular Disease': ['cerebrovascular disease', 'stroke', 'CVA', 'cerebrovascular accident'],\n","    'Dementia': ['dementia', 'Alzheimer\\'s disease', 'alzheimer'],\n","    'Chronic Pulmonary Disease': ['chronic pulmonary disease', 'COPD', 'chronic obstructive pulmonary disease', 'emphysema', 'chronic bronchitis'],\n","    'Connective Tissue Disease': ['connective tissue disease', 'lupus', 'rheumatoid arthritis', 'systemic lupus erythematosus', 'SLE'],\n","    'Peptic Ulcer Disease': ['peptic ulcer disease', 'PUD', 'stomach ulcer', 'gastric ulcer'],\n","    'Mild Liver Disease': ['mild liver disease', 'chronic hepatitis', 'hepatitis B', 'hepatitis C'],\n","    'Diabetes without Complication': ['diabetes', 'diabetes mellitus'],\n","    'Diabetes with Complication': ['diabetic retinopathy', 'diabetic nephropathy', 'diabetes with complications', 'diabetic neuropathy'],\n","    'Hemiplegia or Paraplegia': ['hemiplegia', 'paraplegia', 'paralysis'],\n","    'Renal Disease': ['renal disease', 'chronic kidney disease', 'CKD', 'kidney failure', 'chronic renal failure', 'reduced kidney function'],\n","    'Cancer (non-metastatic)': ['cancer', 'tumor', 'carcinoma', 'malignancy'],\n","    'Leukemia': ['leukemia', 'blood cancer'],\n","    'Lymphoma': ['lymphoma', 'lymphatic cancer', 'Hodgkin\\'s lymphoma', 'non-Hodgkin\\'s lymphoma'],\n","    'Moderate or Severe Liver Disease': ['cirrhosis', 'severe liver disease', 'liver cirrhosis', 'end-stage liver disease'],\n","    'Metastatic Solid Tumor': ['metastatic cancer', 'metastasis',  'metastatic', 'stage IV', 'advanced cancer'],\n","    'AIDS': ['AIDS', 'HIV', 'acquired immunodeficiency syndrome', 'human immunodeficiency virus'],\n","    'Osteoporosis':['osteoporosis']}"]},{"cell_type":"markdown","metadata":{"id":"7SYvAcq95mwa"},"source":["## Running"]},{"cell_type":"markdown","metadata":{"id":"6YYutOnI6JQn"},"source":["Working code, includes per timepoints"]},{"cell_type":"code","source":["# Convert 'MHTERM' to lowercase to ensure case-insensitive matching\n","conditions['MHTERM_lower'] = conditions['MHTERM'].str.lower()\n","\n","# Merge conditions and events on 'PATNO'\n","merged_df = pd.merge(MDS3, conditions, on='PATNO', suffixes=('_event', '_condition'))\n","\n","# Initialize an empty list to collect results\n","results = []\n","\n","# Function to check if any condition term is in the disease name\n","def check_conditions(disease_name):\n","    if not isinstance(disease_name, str):\n","        return []\n","    conditions_found = []\n","    for condition, terms in charlson_conditions.items():\n","        if any(term in disease_name for term in terms):\n","            conditions_found.append(condition)\n","    return conditions_found\n","\n","# Determine the active status of each condition for each timepoint\n","for index, row in merged_df.iterrows():\n","    diag_date = pd.to_datetime(row['MHDIAGDT'], format='%m/%Y')\n","    info_date = pd.to_datetime(row['INFODT_event'], format='%m/%Y')\n","    resolved_date = pd.to_datetime(row['RESDT'], format='%m/%Y') if pd.notna(row['RESDT']) else None\n","\n","    # Initialize conditions for this patient and event\n","    patient_condition = {'PATNO': row['PATNO'], 'EVENT_ID': row['EVENT_ID_event']}\n","    for condition in charlson_conditions.keys():\n","        patient_condition[condition] = 0\n","\n","    # Calculate years since diagnosis for \"BL\" and \"SC\" timepoints, only if the diagnosis was discovered on or before the timepoint\n","    if row['EVENT_ID_event'] in ['BL', 'SC']:\n","        if diag_date <= info_date:\n","            years_since_diag = (info_date.year - diag_date.year) + (info_date.month - diag_date.month) / 12.0\n","            conditions_found = check_conditions(row['MHTERM_lower'])\n","            for condition in conditions_found:\n","                patient_condition[condition] = years_since_diag\n","    else:\n","        # Check if the diagnosis was active at the timepoint\n","        if (diag_date <= info_date) and (row['RESOLVD'] == 0 or (resolved_date and resolved_date >= info_date)):\n","            conditions_found = check_conditions(row['MHTERM_lower'])\n","            for condition in conditions_found:\n","                patient_condition[condition] = 1\n","\n","    # Collect the result for this patient and event\n","    results.append(patient_condition)\n","\n","# Create a DataFrame from the collected results\n","patients_conditions = pd.DataFrame(results)\n","\n","# This analysis above yields a code with repetitive values, and even some Falses among Trues for the same timepoint (the True are correct), so let's subset\n","# Define columns to check for \"True\" values\n","columns_to_check = list(charlson_conditions.keys())\n","\n","# Create a column that will be True if any of the columns_to_check are True\n","patients_conditions['any_true'] = patients_conditions[columns_to_check].any(axis=1)\n","\n","# Sort by PATNO, EVENT_ID and the 'any_true' column\n","df_sorted = patients_conditions.sort_values(by=['PATNO', 'EVENT_ID', 'any_true'], ascending=[True, True, False])\n","\n","# Drop duplicates, keeping the first (which has 'True' if there was any)\n","df_deduplicated = df_sorted.drop_duplicates(subset=['PATNO', 'EVENT_ID'], keep='first')\n","\n","# Drop the helper column\n","patients_conditions_correct = df_deduplicated.drop(columns=['any_true'])\n","\n","# Display the first few rows of the resulting DataFrame\n","patients_conditions_correct.head(5)"],"metadata":{"id":"oo4hqkWRzOoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patients_conditions_correct.describe()"],"metadata":{"id":"-ubfCRVk45Yo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Identifying which patients ever had a diagnosis of osteoporosis\n","print('Number of patients with osteoporosis:', len(patients_conditions_correct[patients_conditions_correct['Osteoporosis'] > 1]))\n","patients_conditions_correct[patients_conditions_correct['Osteoporosis'] > 1].head()"],"metadata":{"id":"VWgBwQr9ng9R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aP8wte5F5Yei"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"M0pf77b86OiF"},"source":["Doing some testing to confirm the accuracy of these measures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0hqvR80Jt0p"},"outputs":[],"source":["# Reshape the DataFrame to long format\n","long_df = pd.melt(patients_conditions_correct, id_vars=['PATNO', 'EVENT_ID'], var_name='Cancer (non-metastatic)', value_name='Status')\n","\n","# Group by PATNO and Condition, then check if there are both True and False values\n","grouped = long_df.groupby(['PATNO', 'Cancer (non-metastatic)'])['Status'].agg(['any', 'all']).reset_index()\n","\n","# Find PATNOs with both True and False statuses for the same condition\n","testing = grouped[(grouped['any'] == True) & (grouped['all'] == False)]\n","testing.head(10)"]},{"cell_type":"markdown","source":["For privacy reasons, I can't share individual patient's data, even as a comment section. I encourage you to look out for some PATNOs for the description of their conditions (see code above) and confirm in the original dataset if the code was able to extract it!"],"metadata":{"id":"qZF6EsQ4q8yR"}},{"cell_type":"markdown","metadata":{"id":"xqvFVlf9Wrmo"},"source":["Exporting"]},{"cell_type":"code","source":["# Exporting\n","patients_conditions_correct.to_csv('data/Medical Conditions.csv', index=False)"],"metadata":{"id":"5Ekq3Wu7waDW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okHdtZ9cOMCY"},"source":["# Medications\n","\n","Several medications are associated with a lower/higher PD risk and/or progression. So having a way to understand in more detail each patient's non-PD medication may be useful for correlation analyses.\n","\n","**Necessary PPMI datasets:** Concomitant Medication Log and MDS-UPDRS Part III Treatment Determination and Part III: Motor Examination\n","\n","**Last Update:** February 9, 2025\n","\n","**Useful links to find all the different names a medication can have:**\n","\n","Link 1: https://go.drugbank.com/\n","\n","Link 2: https://www.rxlist.com/search/rxl/exenat\n"]},{"cell_type":"markdown","metadata":{"id":"YzZgbQWHYgYK"},"source":["### Reading"]},{"cell_type":"markdown","source":["Reading MDS data to use as a surrogate for the timepoints"],"metadata":{"id":"WE8wgg-BsOjn"}},{"cell_type":"code","source":["# Using MDS3 as a timepoint proxy\n","MDS3 = pd.read_csv('data/MDS-UPDRS_Part_III_09Feb2025.csv')\n","print('Lenght of the dataset:', len(MDS3))\n","MDS3.head()"],"metadata":{"id":"jEApGiAssIJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kzw_AmIVYhax"},"outputs":[],"source":["# Reading the medication dataset\n","medications = pd.read_csv('data/Concomitant_Medication_Log_09Feb2025.csv')\n","medications.head(5)"]},{"cell_type":"markdown","source":["Looking at an example drawn from GLP-1 agonists"],"metadata":{"id":"OFappR6esnm4"}},{"cell_type":"code","source":["# Getting columns with the diagnosis we want\n","elements = ['liraglutide', 'victoza', 'saxenda']\n","\n","# Converting 'elements' to lowercase to ensure case-insensitive matching\n","elements_lower = [element.lower() for element in elements]\n","\n","# Selecting the patients that have one of the criterias\n","tempdf = medications[medications['CMTRT'].astype(str).str.lower().apply(lambda x: any(element in x for element in elements))]\n","print('Lenght of patients with the desired condition:', len(tempdf))\n","print('Different values of the obtained dataset:', list(set(tempdf['CMTRT']))) # Printing without duplicates\n","tempdf.head()"],"metadata":{"id":"bhwm8yMXaBqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating doses for medications\n","\n","There are multiple ways to describe a medication dosage. This part of the code tries to interpret the strings written in an organized manner to consolidate everything"],"metadata":{"id":"vJ-OWQJJY6iV"}},{"cell_type":"code","source":["# Identifying different pattern in informing dosage\n","top_elements = medications['CMDOSFRQ'].value_counts().index[:100] # This is the number of unique entries\n","\n","# Criar um novo dataset com um exemplo de cada um dos 30 elementos mais comuns\n","new_df = medications[medications['CMDOSFRQ'].isin(top_elements)].drop_duplicates(subset=['CMDOSFRQ'])\n","\n","# Show\n","list(new_df['CMDOSFRQ'].value_counts().index.tolist())"],"metadata":{"id":"wzjlNTRnDdid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Doses dict setting\n","# This is a dict that uses the most common used terms to describe each regimen\n","# The keys are values that will be used to multiply the dose\n","# The values are names that represent those concepts\n","\n","daily_dose = {\n","    '1': ['QD', 'SD', 'OD', 'QHS', 'DAILY', '1X', 'HS',\n","          'X1', 'QAM', 'QPM', '1XQD', 'NOCTE', '1 X QD', '1X WEEKLY',\n","          ' QD', 'QS', 'X1', 'QPM', 'QAM', 'QDHS'],  # Once daily\n","    '2': ['BID', '2X', 'BD', 'QAD', '2 X DAILY', 'TDS', 'TT OD'],  # Twice daily\n","    '3': ['TID', '3/DAY', '3X', 'TDS'],  # Thrice daily\n","    '4': ['QID', 'QDS', '4/DAY', 'Q6H', '4X', '4XD', '4XQD', 'TDS'],  # Four times a day\n","    '6': ['Q4H', '6XD', '6XDAY'],  # Six times a day\n","    '0.5': ['QOD', 'EOD', 'QAD', 'Q48H', 'ALT DAY', 'Q2 DAYS', 'Q 2 DAYS'],  # Every two days\n","    '0.714': ['TIW', '3X/WEEK', '3X WEEK', '3X A WEEK'],  # Thrice a week\n","    '0.429': ['5X WEEK', '5XWK'],  # Five times a week\n","    '0.2857': ['BIW', '2/WEEK', '2X WEEK'],  # Twice a week\n","    '0.1429': ['QW', 'QWK', 'WEEKLY', 'QWEEK', 'X1/WK', '1XWK', 'QIW', '1X WEEK', 'WK', '1/WK',\n","               'Q WK', '1XWEEK', '1/WEEK', 'Q1WK', 'QWEEKLY'],  # Weekly\n","    '0.0714': ['Q2WK'], # Every two weeks\n","    '0.0333': ['MONTHLY', 'QM', '1XMONTH', '1/MONTH', 'QMONTH', 'Q4WK', '1X MONTH', 'MONTH'],  # Monthly\n","    '0.0111': ['Q3MONTH', 'Q3MON', 'Q 3 MONTHS', 'Q3 MOS', 'Q3M','EVERY 3 MO', 'Q3MOS', 'Q3 MONTH'],  # Every three months\n","    '0.0056': ['Q6M', 'Q6MONTHS', 'Q 6 MONTHS', 'Q6MTHS']  # Every 6 months\n","}"],"metadata":{"id":"t8n2LYx2Y_Uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert CMDOSFRQ to lowercase\n","medications['CMDOSFRQ_lower'] = medications['CMDOSFRQ'].str.lower()\n","\n","# Function to find the multiplication factor\n","def get_multiplication_factor(dosage_frequency):\n","    for factor, terms in daily_dose.items():\n","        if dosage_frequency in [term.lower() for term in terms]:\n","            return float(factor)\n","    return None  # Default factor if no match is found\n","\n","# Apply the function to each row\n","medications['dose_factor'] = medications['CMDOSFRQ_lower'].apply(get_multiplication_factor)\n","\n","# Calculate the final dose\n","medications['final_dose'] = medications['CMDOSE'] * medications['dose_factor']\n","\n","# Drop the helper column\n","medications = medications.drop(columns=['CMDOSFRQ_lower'])\n","\n","# Display the result\n","medications[['CMTRT','CMDOSE','CMDOSU','CMDOSFRQ','dose_factor','final_dose']].head(5)"],"metadata":{"id":"XOaOAyVHY8Cx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's do some testing with groups of medications"],"metadata":{"id":"N2xc5Fv2hHGj"}},{"cell_type":"code","source":["# Combined dictionary of medications with prefixes\n","medications_dict = {\n","    'glp1_Exenatide': ['exenatide', 'byetta', 'bydureon'],\n","    'glp1_Liraglutide': ['liraglutide', 'victoza', 'saxenda', 'Xultophy'],\n","    'glp1_Lixisenatide': ['lixisenatide', 'adlyxin', 'lyxumia', 'Soliqua'],\n","    'glp1_Dulaglutide': ['dulaglutide', 'trulicity'],\n","    'glp1_Semaglutide': ['semaglutide', 'ozempic', 'rybelsus', 'Wegovy'],\n","    'glp1_Albiglutide': ['albiglutide', 'tanzeum', 'eperzan'],\n","    'glp1_Efpeglenatide': ['efpeglenatide'],\n","    'glp1_Tirzepatide': ['tirzepatide', 'mounjaro', 'zepbound']}"],"metadata":{"id":"Nx8qTx3uhJJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Running the function\n","\n","This function will identify, at each specific timepoint, if the patient was taking the medication or not. It will also try to calculate the dosage of that specific medication the patient was taking at each timepoint.\n","\n","At each medication's column, whenever positive, it will also calculate how many years have passed since the patient's initiation of motor symptoms and that specific timepoint being analysed. So, for example, if a patient is taking liraglutide roughly since the year his disease started and his first BL or SC visit is 2 years after the beginning of his symptoms, that column for BL or SC will be 2."],"metadata":{"id":"J--dmvkUjlbH"}},{"cell_type":"code","source":["# Convert 'CMTRT' to lowercase to ensure case-insensitive matching\n","medications['CMTRT_lower'] = medications['CMTRT'].str.lower()\n","\n","# Merge conditions and events on 'PATNO'\n","merged_df = pd.merge(MDS3, medications, on='PATNO', suffixes=('_event', '_medication'))\n","\n","# Initialize an empty list to collect results\n","results = []\n","\n","# Function to check if any medication term is in the medication name\n","def check_medications(medication_name):\n","    if not isinstance(medication_name, str):\n","        return []\n","    medications_found = []\n","    for medication, terms in medications_dict.items():\n","        if any(term in medication_name for term in terms):\n","            medications_found.append(medication)\n","    return medications_found\n","\n","# Determine the active status and dose of each medication for each timepoint\n","for index, row in merged_df.iterrows():\n","    diag_date = pd.to_datetime(row['STARTDT'], format='%m/%Y')\n","    info_date = pd.to_datetime(row['INFODT'], format='%m/%Y')\n","    resolved_date = pd.to_datetime(row['STOPDT'], format='%m/%Y') if pd.notna(row['STOPDT']) else None\n","\n","    # Initialize medications for this patient and event\n","    patient_medication = {'PATNO': row['PATNO'], 'EVENT_ID': row['EVENT_ID_event']}\n","    patient_medication_dose = {'PATNO': row['PATNO'], 'EVENT_ID': row['EVENT_ID_event']}\n","    for medication in medications_dict.keys():\n","        patient_medication[medication] = 0\n","        patient_medication_dose[medication + '_dose'] = None\n","\n","    # Calculate years since diagnosis for \"BL\" and \"SC\" timepoints, only if the diagnosis was discovered on or before the timepoint\n","    if row['EVENT_ID_event'] in ['BL', 'SC']:\n","        if diag_date <= info_date:\n","            years_since_diag = (info_date.year - diag_date.year) + (info_date.month - diag_date.month) / 12.0\n","            medications_found = check_medications(row['CMTRT_lower'])\n","            for medication in medications_found:\n","                patient_medication[medication] = years_since_diag\n","    else:\n","        # Check if the medication was active at the timepoint\n","        if (diag_date <= info_date) and (resolved_date is None or resolved_date >= info_date):\n","            medications_found = check_medications(row['CMTRT_lower'])\n","            for medication in medications_found:\n","                patient_medication[medication] = 1\n","                patient_medication_dose[medication + '_dose'] = row['final_dose']\n","\n","    # Collect the result for this patient and event\n","    results.append({**patient_medication, **patient_medication_dose})\n","\n","# Create a DataFrame from the collected results\n","patients_medications = pd.DataFrame(results)\n","\n","# Define columns to check for \"True\" values\n","columns_to_check = list(medications_dict.keys())\n","\n","# Create a column that will be True if any of the columns_to_check are True\n","patients_medications['any_true'] = patients_medications[columns_to_check].any(axis=1)\n","\n","# Sort by PATNO, EVENT_ID and the 'any_true' column\n","df_sorted = patients_medications.sort_values(by=['PATNO', 'EVENT_ID', 'any_true'], ascending=[True, True, False])\n","\n","# Drop duplicates, keeping the first (which has 'True' if there was any)\n","df_deduplicated = df_sorted.drop_duplicates(subset=['PATNO', 'EVENT_ID'], keep='first')\n","\n","# Drop the helper column\n","patients_medications_correct = df_deduplicated.drop(columns=['any_true'])\n","\n","# Display the result\n","patients_medications_correct.head()"],"metadata":{"id":"8SwqjuU1jlI3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking moments in which a patient is taking Liraglutide"],"metadata":{"id":"r4JupHR6tm8Q"}},{"cell_type":"code","source":["# Identifying which patients ever had a diagnosis of osteoporosis\n","print('Number of patients with liraglutide use:', len(patients_medications_correct[patients_medications_correct['glp1_Liraglutide'] > 1]))\n","patients_medications_correct[patients_medications_correct['glp1_Liraglutide'] > 1].head()"],"metadata":{"id":"KjBXk4vtt1iv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GWna-3IuQUO"},"source":["## Testing"]},{"cell_type":"markdown","metadata":{"id":"vthfHTNLuQUU"},"source":["Doing some testing to confirm the accuracy of these measures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IY2xU-uDuQUU"},"outputs":[],"source":["# Reshape the DataFrame to long format\n","long_df = pd.melt(patients_medications_correct, id_vars=['PATNO', 'EVENT_ID'], var_name='glp1_Liraglutide', value_name='Status')\n","\n","# Group by PATNO and Condition, then check if there are both True and False values\n","grouped = long_df.groupby(['PATNO', 'glp1_Liraglutide'])['Status'].agg(['any', 'all']).reset_index()\n","\n","# Find PATNOs with both True and False statuses for the same condition\n","testing = grouped[(grouped['any'] == True) & (grouped['all'] == False)]\n","testing.head(10)"]},{"cell_type":"markdown","source":["For privacy reasons, I can't share individual patient's data, even as a comment section. I encourage you to look out for some PATNOs for the description of their conditions (see code above) and confirm in the original dataset if the code was able to extract it!"],"metadata":{"id":"ddjjdDlxwVpk"}},{"cell_type":"markdown","source":["Exporting"],"metadata":{"id":"R5vOXDHybwJ8"}},{"cell_type":"code","source":["# Exporting\n","patients_medications_correct.to_csv('data/Non PD Medications.csv', index=False)"],"metadata":{"id":"_jXqy4AnwjNF"},"execution_count":null,"outputs":[]}]}