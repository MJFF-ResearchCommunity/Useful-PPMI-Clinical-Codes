{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8woFzbSOyoxy"
   },
   "source": [
    "# Introduction to this Notebook\n",
    "\n",
    "This Jupyter Notebook encompassess a series of scripts written in Python by Daniel Teixeira dos Santos, a Data Community Innovator at the Data Community of Practice ([link to my forum account](https://rcop.michaeljfox.org/u/danieltds/summary)). These scripts were written using data from PPMI, obtained through LONI. These files are linked to the MJFF Research Community's GitHub repository ([link here](https://github.com/MJFF-ResearchCommunity/Useful-PPMI-Clinical-Codes))\n",
    "\n",
    "The goal of these scripts is to provide researchers some relevant clinical data that are extracted in a meaningful way form the data that is already available in PPMI. All the necessary input datasets can be obtained [here](https://ida.loni.usc.edu/pages/access/studyData.jsp?project=PPMI) after applying for registration for access to the PPMI data. All outputs from the analyses were removed to comply with privacy and data sharing principles. Some of these scripts were developed with the help of AI tools such as ChatGPT 4o.\n",
    "\n",
    "This analysis requires two different folders to exist within the main folder. Those are \"data\" and \"priv\". The \"data\" folder is the place where you should store your datasets downloaded from LONI. The priv folder is the one the results will be exported to. These folders will be generated automatically at the beginning of this script, if they don't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT3aJYfg_HsV"
   },
   "source": [
    "# Importing and Setting Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2U67csL_KgD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# Automatically find the \"Useful PPMI Clinical Codes\" directory\n",
    "CURRENT_DIR = os.getcwd()\n",
    "while not CURRENT_DIR.endswith(\"Useful PPMI Clinical Codes\") and os.path.dirname(CURRENT_DIR) != CURRENT_DIR:\n",
    "    CURRENT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "\n",
    "BASE_DIR = CURRENT_DIR\n",
    "\n",
    "# Define paths for \"data\" and \"report\" directories\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "PRIV_DIR = os.path.join(BASE_DIR, \"priv\")\n",
    "\n",
    "# Ensure both directories exist, create them if not\n",
    "for directory in [DATA_DIR, PRIV_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created missing folder: {directory}\")\n",
    "    else:\n",
    "        print(f\"Found folder: {directory}\")\n",
    "\n",
    "# Ignore persistent warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# Configure Pandas for better data visualization\n",
    "pd.set_option('display.max_rows', 250)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "# List available files in both directories\n",
    "print(\"Files in data directory:\", os.listdir(DATA_DIR))\n",
    "print(\"Files in priv directory:\", os.listdir(PRIV_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXWddGqI3Ldo"
   },
   "source": [
    "# Levodopa responsiveness\n",
    "\n",
    "Levodopa responsiveness is a very interesting marker that different studies have approached (example: https://pubmed.ncbi.nlm.nih.gov/38898616/). The PPMI protocol states that, whenever possible, patients should be evaluated both in the OFF and ON states. In that way, we can calculate levodopa challenge responses by using the formula: response = (off - on) / off x 100. A good levodopa response is (usually at least 30%), for example, a pre-requisite for DBS surgery.\n",
    "\n",
    "**Necessary PPMI datasets:** MDS-UPDRS Part III Treatment Determination and Part III: Motor Examination\n",
    "\n",
    "**Last Update:** February 9, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX9s1vYZLQna"
   },
   "source": [
    "## Organizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP0cxU2FPWqG"
   },
   "source": [
    "### General read and view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC229wdVB8vK"
   },
   "outputs": [],
   "source": [
    "MDS3 = pd.read_csv(os.path.join(DATA_DIR, \"MDS-UPDRS_Part_III_09Feb2025.csv\"))\n",
    "print('Lenght of the dataset:', len(MDS3))\n",
    "MDS3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqVvHXYUwriv"
   },
   "outputs": [],
   "source": [
    "# Define concepts with their corresponding columns\n",
    "# This can be useful to calculate characteristic-specific levodopa responses\n",
    "concepts = {\n",
    "    'Rigidity': [\"NP3RIGLL\", \"NP3RIGLU\", \"NP3RIGN\", \"NP3RIGRL\", \"NP3RIGRU\"], # 3.3 (all elements)\n",
    "    \"Tremor\": [\"NP3KTRML\", \"NP3KTRMR\", \"NP3PTRML\", \"NP3PTRMR\", \"NP3RTALJ\", \"NP3RTALL\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTARU\", \"NP3RTCON\"], # 3.15 + 3.16 + 3.17 + 3.18\n",
    "    \"Gait_and_Posture\": [\"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\", \"NP3POSTR\"], # 3.9 + 3.10 + 3.11 + 3.12 + 3.13\n",
    "    \"Bradykinesia\": [\"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\", \"NP3TTAPL\", \"NP3LGAGR\", \"NP3LGAGL\", \"NP3BRADY\"],# \t3.4 + 3.5 + 3.6 + 3.7 + 3.8 + 3.14\n",
    "    'All_MDS3': [\"NP3SPCH\", \"NP3FACXP\", \"NP3RIGN\", \"NP3RIGRU\", \"NP3RIGLU\", \"NP3RIGRL\", \"NP3RIGLL\",\n",
    "    \"NP3FTAPR\", \"NP3FTAPL\", \"NP3HMOVR\", \"NP3HMOVL\", \"NP3PRSPR\", \"NP3PRSPL\", \"NP3TTAPR\",\n",
    "    \"NP3TTAPL\", \"NP3LGAGR\", \"NP3LGAGL\", \"NP3RISNG\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\",\n",
    "    \"NP3POSTR\", \"NP3BRADY\", \"NP3PTRMR\", \"NP3PTRML\", \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\",\n",
    "    \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \"NP3RTALJ\", \"NP3RTCON\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PNS_SOfwtO2"
   },
   "outputs": [],
   "source": [
    "# Function to compute the sum, considering NaN\n",
    "def sum_with_nan(series):\n",
    "    if series.isna().any():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return series.sum()\n",
    "\n",
    "concepts_list = []\n",
    "\n",
    "# Add new columns with the sum of values for each concept\n",
    "for concept, columns in concepts.items():\n",
    "    sum_column = concept\n",
    "    concepts_list.append(sum_column)\n",
    "    MDS3[sum_column] = MDS3[columns].apply(sum_with_nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCap9oFlGQEa"
   },
   "outputs": [],
   "source": [
    "# Let's check the overall distribution of the PDSTATE (situation in which the patient was examined)\n",
    "MDS3['PDSTATE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrPQhVbxhzJJ"
   },
   "source": [
    "Check how many different entries (more than one for patient) have at least 2 MDS evaluations (one in the OFF and one in the ON states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTtY5lpSEAQ6"
   },
   "outputs": [],
   "source": [
    "# Group by PATNO and EVENT_ID and filter groups with more than one entry\n",
    "duplicates = MDS3.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n",
    "result_test = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n",
    "    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n",
    "    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n",
    "    'EXAMTM': lambda x: tuple(x), # Time of NUPDRS3 exam\n",
    "    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n",
    "    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n",
    "    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n",
    "    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n",
    "    'OFFNORSN': lambda x: tuple(x), # Reason OFF exam not performed\n",
    "    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n",
    "    'ONEXAM': lambda x: tuple(x), # ON exam performed\n",
    "    'ONNORSN': lambda x: tuple(x), # Reason ON exam not performed\n",
    "    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n",
    "    'PDMEDDT': lambda x: tuple(x), # Date of most recent PD med dose before exam\n",
    "    'PDMEDTM': lambda x: tuple(x), # Time of most recent PD med dose before exam\n",
    "}).reset_index()\n",
    "\n",
    "print('Lenght of the dataset considering at least 2 evaluations:', len(result_test))\n",
    "result_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY65-iefh7XT"
   },
   "source": [
    "Check how many different entries (more than one for patient) have at least 3 MDS evaluations (one in the OFF and one in the ON states).\n",
    "\n",
    "This is unusual, but the number is low. Did this just to check how data are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTHjrGyVO4zy"
   },
   "outputs": [],
   "source": [
    "# Group by PATNO and EVENT_ID and filter groups with more than one entry\n",
    "duplicates = MDS3.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) > 2)\n",
    "\n",
    "# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n",
    "result_test = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n",
    "    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n",
    "    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n",
    "    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n",
    "    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n",
    "    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n",
    "    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n",
    "    'OFFNORSN': lambda x: tuple(x), # Reason OFF exam not performed\n",
    "    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n",
    "    'ONEXAM': lambda x: tuple(x), # ON exam performed\n",
    "    'ONNORSN': lambda x: tuple(x), # Reason ON exam not performed\n",
    "    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n",
    "    'PDMEDDT': lambda x: tuple(x), # Date of most recent PD med dose before exam\n",
    "    'PDMEDTM': lambda x: tuple(x), # Time of most recent PD med dose before exam\n",
    "}).reset_index()\n",
    "\n",
    "print('Lenght of the dataset considering more than 2 evaluations:', len(result_test))\n",
    "result_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTqQTuw2PaJh"
   },
   "source": [
    "### Missing correction\n",
    "\n",
    "Missing values in the MDS-UPDRS can be written as 101 (Unable to Rate). Let's identify those and treat them as NaN for our analysis not to be biased by those high numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdnrXA42MOiP"
   },
   "outputs": [],
   "source": [
    "# Dataset has some \"101\", which are \"Unable to Rate\"\n",
    "MDS3['NP3RIGLL'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VaRjqVbMa-j"
   },
   "outputs": [],
   "source": [
    "# Converting unables to rate to nan\n",
    "MDS3 = MDS3.replace(101,np.nan)\n",
    "\n",
    "# Forcing to become float, ignore errors\n",
    "MDS3 = MDS3.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Checking\n",
    "MDS3['NP3RIGLL'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er_StgOzPdyB"
   },
   "source": [
    "### DBS categories\n",
    "\n",
    "Patients also undergo DBS as this is informed in the MDS3 scale. We will want, in this code, generate separate values for evaluations that had a DBS and evaluations without a DBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxY8tVcRPhV-"
   },
   "outputs": [],
   "source": [
    "print('Length of the dataset before removing DBS:', len(MDS3))\n",
    "MDS3_nodbs = MDS3[MDS3['DBSYN'].isin([0, np.nan])].reset_index(drop=True)\n",
    "print('Length of the dataset after removing DBS:', len(MDS3_nodbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTGdIP6IxA0g"
   },
   "outputs": [],
   "source": [
    "print('Length of the dataset before subsetting by DBS:', len(MDS3))\n",
    "MDS3_dbs = MDS3[MDS3['DBSYN'].isin([1])].reset_index(drop=True)\n",
    "print('Length of the dataset after subsetting by DBS:', len(MDS3_dbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tIwup-yQJs6"
   },
   "source": [
    "## Calculating response (no DBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ER0375dQMK2"
   },
   "outputs": [],
   "source": [
    "# Group by PATNO and EVENT_ID and filter groups with more than one entry\n",
    "duplicates = MDS3_nodbs.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) == 2)\n",
    "\n",
    "# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n",
    "result = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n",
    "    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n",
    "    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n",
    "    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n",
    "    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n",
    "    'ONEXAM': lambda x: tuple(x), # ON exam performed\n",
    "    'Rigidity': lambda x: tuple(x), # Rigidity\n",
    "    'Tremor': lambda x: tuple(x), # Tremor\n",
    "    'Gait_and_Posture': lambda x: tuple(x), # Gait and Posture\n",
    "    'Bradykinesia': lambda x: tuple(x), # Bradykinesia\n",
    "    'All_MDS3': lambda x: tuple(x), # MDS_3 Complete\n",
    "}).reset_index()\n",
    "\n",
    "print('Lenght of the dataset considering exactly 2 evaluations:', len(result))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLx-cVZijLUz"
   },
   "source": [
    "Main function to calculate the response. It uses the tuples of OFF and ON to calculate these responses, then generates new columns detailing the actual responses. There are also other columns that helps us better understaning what is happening, such as \"Time_since_levodopa\", which helps us be sure that the responses are correctly calculating OFF versus ON responses, and not the opposite.\n",
    "\n",
    "The lowest HRPOSTMED (hours after last medication) is used to define the ON state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QeI-M4VSd9s"
   },
   "outputs": [],
   "source": [
    "# Define the function to calculate the response\n",
    "def calculate_response(on, off):\n",
    "    if pd.isna(on) or pd.isna(off) or off == 0:\n",
    "        return np.nan\n",
    "    return ((off - on) / off) * 100\n",
    "\n",
    "# Define a function to round values and handle errors\n",
    "def round_to_int(value):\n",
    "    try:\n",
    "        return int(round(value))\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "# Function to process the dataset\n",
    "def process_dataset(df, concepts_list):\n",
    "    new_columns = []\n",
    "    df['Time_since_levodopa'] = df['HRPOSTMED'].apply(lambda x: min(x) if not any(pd.isna(v) for v in x) else np.nan) * 60  # Convert to minutes\n",
    "    df['Time_since_levodopa'] = df['Time_since_levodopa'].apply(round_to_int)\n",
    "    for var in concepts_list:\n",
    "        new_col_name = f'{var}_resp'\n",
    "        new_columns.append(new_col_name)\n",
    "        df[new_col_name] = df.apply(lambda row: calculate_response(\n",
    "            row[var][0] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][1],  # on\n",
    "            row[var][1] if not any(pd.isna(v) for v in row['HRPOSTMED']) and row['HRPOSTMED'][0] < row['HRPOSTMED'][1] else row[var][0]   # off\n",
    "        ) if not any(pd.isna(v) for v in row['HRPOSTMED']) else np.nan, axis=1)\n",
    "    return df, new_columns\n",
    "\n",
    "# Run the function\n",
    "levodopa_response, newcols = process_dataset(result, concepts_list)\n",
    "\n",
    "# Remove those that don't have info on time since levodopa\n",
    "filtered_df = levodopa_response[levodopa_response['Time_since_levodopa'].notna()]\n",
    "\n",
    "# Count the unique values in the 'Time_since_levodopa' column\n",
    "unique_patients_levodopa = filtered_df['Time_since_levodopa'].nunique()\n",
    "print('Length of entire dataset:', len(levodopa_response))\n",
    "print('Length of subsetted dataset:', len(filtered_df))\n",
    "print('Number of unique patients NOT using DBS that took levodopa in a challenge:', unique_patients_levodopa)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "levodopa_response.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTd3vogqWlQx"
   },
   "source": [
    "There are some negative values, however, they are a minority of the data. Some of the most significant ones can be typos, and other just a slight paradoxical worsening / variation due to clinician's judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwr09tmdWlBj"
   },
   "outputs": [],
   "source": [
    "levodopa_response[newcols].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFwCdw-okLen"
   },
   "outputs": [],
   "source": [
    "# First, let's have a general idea of some patients with negative responses\n",
    "print(len(levodopa_response[levodopa_response['All_MDS3_resp'] < 0]))\n",
    "levodopa_response[levodopa_response['All_MDS3_resp'] < 0].head(10)[['PDSTATE','HRPOSTMED','All_MDS3','All_MDS3_resp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFk8d3r4oIjD"
   },
   "outputs": [],
   "source": [
    "# Second, let's have a general idea of some patients with EXTREME negative responses\n",
    "print(len(levodopa_response[levodopa_response['All_MDS3_resp'] < -100]))\n",
    "levodopa_response[levodopa_response['All_MDS3_resp'] < -100].head(10)[['PDSTATE','HRPOSTMED','All_MDS3','All_MDS3_resp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_d9clp_toVzA"
   },
   "source": [
    "As you can see, most patients with responses between -100 and 0 have just a mild paradoxical response or variation due to clinical judgment. However, most patients < -100 probably have typos that invalidated the analysis. Fortunately, thery are only a few.\n",
    "\n",
    "I will not remove those, but **I highly suggest you take that into account in your analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kdmmJ2wxwqW"
   },
   "source": [
    "Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LkMtKNixx39"
   },
   "outputs": [],
   "source": [
    "# Exporting\n",
    "levodopa_response.to_csv(os.path.join(PRIV_DIR, \"Levodopa_challenge_no_DBS.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fqafPVYxUSY"
   },
   "source": [
    "## Calculating response (DBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEARecrSxUSY"
   },
   "outputs": [],
   "source": [
    "# Group by PATNO and EVENT_ID and filter groups with more than one entry\n",
    "duplicates = MDS3_dbs.groupby(['PATNO', 'EVENT_ID']).filter(lambda x: len(x) == 2)\n",
    "\n",
    "# Extract unique PATNO and EVENT_ID pairs with values in the specified columns\n",
    "result = duplicates.groupby(['PATNO', 'EVENT_ID']).agg({\n",
    "    'PDSTATE': lambda x: tuple(x), # Which functional state is the participant currently in?\n",
    "    'HRPOSTMED': lambda x: tuple(x), # Hours between last dose of PD medication and NUPDRS3 exam\n",
    "    'EXAMTM': lambda x: tuple(x), # Time of NUPDRS3 exam\n",
    "    'ONOFFORDER': lambda x: tuple(x), # First Part III exam OFF or ON\n",
    "    'OFFEXAM': lambda x: tuple(x), # OFF exam performed\n",
    "    'ONEXAM': lambda x: tuple(x), # ON exam performed\n",
    "    'DBSYN': lambda x: tuple(x), # Does participant have DBS\n",
    "    'DBSOFFTM': lambda x: tuple(x), # Time DBS turned off before OFF exam\n",
    "    'DBSONTM': lambda x: tuple(x), # Time DBS turned on before ON exam\n",
    "    'HRDBSON': lambda x: tuple(x), # Hours between DBS device turned on and NUPDRS3 exam\n",
    "    'Rigidity': lambda x: tuple(x), # Rigidity\n",
    "    'Tremor': lambda x: tuple(x), # Tremor\n",
    "    'Gait_and_Posture': lambda x: tuple(x), # Gait and Posture\n",
    "    'Bradykinesia': lambda x: tuple(x), # Bradykinesia\n",
    "    'All_MDS3': lambda x: tuple(x), # MDS_3 Complete\n",
    "}).reset_index()\n",
    "\n",
    "print('Lenght of the dataset considering exactly 2 evaluations:', len(result))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbTi9oEcxUSZ"
   },
   "outputs": [],
   "source": [
    "# Run the function\n",
    "levodopa_response, newcols = process_dataset(result, concepts_list)\n",
    "\n",
    "# Remove those that don't have info on time since levodopa\n",
    "filtered_df = levodopa_response[levodopa_response['Time_since_levodopa'].notna()]\n",
    "\n",
    "# Count the unique values in the 'Time_since_levodopa' column\n",
    "unique_patients_levodopa = filtered_df['Time_since_levodopa'].nunique()\n",
    "print('Length of entire dataset:', len(levodopa_response))\n",
    "print('Length of subsetted dataset:', len(filtered_df))\n",
    "print('Number of unique patients using DBS that took levodopa in a challenge:', unique_patients_levodopa)\n",
    "\n",
    "# Showing the subsetted dataset\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt0Cq29jpJ2b"
   },
   "outputs": [],
   "source": [
    "# Exporting\n",
    "levodopa_response.to_csv(os.path.join(PRIV_DIR, \"Levodopa_challenge_DBS.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMI5LItW6Q6uGsdLm7BJvNB",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
